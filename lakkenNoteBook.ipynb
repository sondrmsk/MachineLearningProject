{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_test = pd.read_csv('ais_test.csv')\n",
    "ais_train = pd.read_csv('first_50000_rows.csv', sep='|')\n",
    "\n",
    "# Merge test set with training set history\n",
    "ais_train['time'] = pd.to_datetime(ais_train['time'])  # Ensure time is datetime\n",
    "ais_test['time'] = pd.to_datetime(ais_test['time'])\n",
    "\n",
    "# Sort by vesselId and time\n",
    "ais_train = ais_train.sort_values(['vesselId', 'time'])\n",
    "ais_test = ais_test.sort_values(['vesselId', 'time'])\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate both dataframes in order to add correct time series features\n",
    "\n",
    "# label where data comes from before concatenation\n",
    "ais_train['dataset'] = 'train'\n",
    "ais_test['dataset'] = 'test'\n",
    "\n",
    "combined_df = pd.concat([ais_train, ais_test], ignore_index=True)\n",
    "\n",
    "# Sort by vesselId and time to ensure proper order for calculating lags\n",
    "combined_df = combined_df.sort_values(['vesselId', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW FEATURES: Creating lag features and moving avg.\n",
    "# ONE HOT ENCODING: Navstat is lagged, an then one hot encoded within all lag windows\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Ensure that lag does not point on any other vesselID.\n",
    "\n",
    "# Create lag features (e.g., lag of 1, 2, 3 steps)\n",
    "for lag in [1, 2, 3]:\n",
    "    combined_df[f'sog_lag{lag}'] = combined_df.groupby('vesselId')['sog'].shift(lag).ffill()\n",
    "    combined_df[f'cog_lag{lag}'] = combined_df.groupby('vesselId')['cog'].shift(lag).ffill()\n",
    "    combined_df[f'rot_lag{lag}'] = combined_df.groupby('vesselId')['rot'].shift(lag).ffill()\n",
    "    combined_df[f'heading_lag{lag}'] = combined_df.groupby('vesselId')['heading'].shift(lag).ffill()\n",
    "    combined_df[f'navstat_lag{lag}'] = combined_df.groupby('vesselId')['navstat'].shift(lag).ffill()\n",
    "    combined_df[f'etaRaw_lag{lag}'] = combined_df.groupby('vesselId')['etaRaw'].shift(lag).ffill()\n",
    "    combined_df[f'latitude_lag{lag}'] = combined_df.groupby('vesselId')['latitude'].shift(lag).ffill()\n",
    "    combined_df[f'longitude_lag{lag}'] = combined_df.groupby('vesselId')['longitude'].shift(lag).ffill()\n",
    "    \n",
    "# Adding moving averages on a set of attributes\n",
    "combined_df['sog_ma5'] = combined_df.groupby('vesselId')['sog'].rolling(window=5, min_periods=1).apply(lambda x: x.dropna().mean()).reset_index(0, drop=True)\n",
    "combined_df['cog_ma5'] = combined_df.groupby('vesselId')['cog'].rolling(window=5, min_periods=1).apply(lambda x: x.dropna().mean()).reset_index(0, drop=True)\n",
    "combined_df['rot_ma5'] = combined_df.groupby('vesselId')['rot'].rolling(window=5, min_periods=1).apply(lambda x: x.dropna().mean()).reset_index(0, drop=True)\n",
    "combined_df['heading_ma5'] = combined_df.groupby('vesselId')['heading'].rolling(window=5, min_periods=1).apply(lambda x: x.dropna().mean()).reset_index(0, drop=True)\n",
    "combined_df['latitude_ma5'] = combined_df.groupby('vesselId')['latitude'].rolling(window=5, min_periods=1).apply(lambda x: x.dropna().mean()).reset_index(0, drop=True)\n",
    "combined_df['longitude_ma5'] = combined_df.groupby('vesselId')['longitude'].rolling(window=5, min_periods=1).apply(lambda x: x.dropna().mean()).reset_index(0, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# one-hot encode the lagged navstat lag features\n",
    "lag_columns = ['navstat_lag1', 'navstat_lag2', 'navstat_lag3']\n",
    "combined_df = pd.get_dummies(combined_df, columns=lag_columns, prefix=lag_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split back\n",
    "\n",
    "\n",
    "combined_df = combined_df.drop(columns=['ID', 'cog', 'sog', 'rot', 'heading', 'navstat', 'etaRaw', 'portId'])\n",
    "combined_df\n",
    "\n",
    "# Separate the enriched test set back from combined data\n",
    "ais_test_enriched = combined_df[combined_df['dataset'] == 'test'].copy()\n",
    "ais_train_enriched = combined_df[combined_df['dataset'] == 'train'].copy()\n",
    "\n",
    "# Drop the 'dataset' column as it's no longer needed\n",
    "ais_test_enriched = ais_test_enriched.drop(columns=['dataset', ])\n",
    "ais_train_enriched = ais_train_enriched.drop(columns=['dataset', ])\n",
    "\n",
    "ais_test_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_test_enriched.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in each column\n",
    "null_values = ais_test_enriched.isnull().sum()\n",
    "\n",
    "# Display the result\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
